{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video Link: https://www.youtube.com/watch?v=06VErVj9MaQ&t=1108s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba derives from \"Numpy\" and \"Mamba\". Numba turns Python into a compiled language with a GPU target.\n",
    "\n",
    "[You cannot use the python list and dictionary](https://numba.pydata.org/numba-doc/dev/cuda/cudapysupported.html). If you write in that way, it might be slower. But you can use Numpy array.\n",
    "```\n",
    "The following Python constructs are not supported:\n",
    "- Exception handling\n",
    "- context management (the with statement)\n",
    "- Comprehensions (either list, dict, set or generator comprehensions)\n",
    "- Generator (any yield statments)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Opernsource BSD license\n",
    "- Basic CUDA GPU JIT compilation\n",
    "- OpenCL support coming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numba 0.34.0\n"
     ]
    }
   ],
   "source": [
    "import numba\n",
    "print(\"numba\", numba.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The CUDA GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A massively parallel processor (many cores)\n",
    "    - 100 threads, 1000 threads, and more\n",
    "- optimized for data throughput\n",
    "    - simple (shallow) cache hierarchy\n",
    "    - best with manual caching!\n",
    "    - Cache memory is called shared memory and it is addressable\n",
    "- CPU is latency optimized\n",
    "    - Deep cache hierarchy\n",
    "    - L1, L2 L3 cahces\n",
    "- GPU execution model is different\n",
    "- GPU forces you to think and program in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba.cuda\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU: b'GeForce GTX 1080 Ti'\n"
     ]
    }
   ],
   "source": [
    "my_gpu = numba.cuda.get_current_device()\n",
    "print(\"Running on GPU:\", my_gpu.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute capability:  6.1 (Numba requires >= 2.0)\n"
     ]
    }
   ],
   "source": [
    "cc = my_gpu.compute_capability\n",
    "print(\"Compute capability: \", \"%d.%d\" % cc, \"(Numba requires >= 2.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of streaming multiprocessor: 28\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of streaming multiprocessor:\", my_gpu.MULTIPROCESSOR_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-level Array-Oriented Style\n",
    "- Use NumPy array as a unit of computation\n",
    "- Use NumPy universal function (ufunc) as an abstraction of computation of scheduling\n",
    "- ufuncs are elementwise functions\n",
    "- If you use NumPy, you are using ufuncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ufunc 'sin'> is of type <class 'numpy.ufunc'>\n",
      "<ufunc 'add'> is of type <class 'numpy.ufunc'>\n"
     ]
    }
   ],
   "source": [
    "print(np.sin, \"is of type\", type(np.sin))\n",
    "print(np.add, \"is of type\", type(np.add))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize\n",
    "- generate a ufunc from a python function\n",
    "- converts scalar function to elementwise array function\n",
    "- Numba provides CPU support\n",
    "-  <s>NumbaPro provides GPU support</s>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU version\n",
    "@numba.vectorize(['float32(float32, float32)', \n",
    "                  'float64(float64, float64)'], target = 'cpu')\n",
    "def cpu_sincos(x, y):\n",
    "    return math.sin(x) * math.cos(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: \n",
    "- https://numba.pydata.org/numba-doc/latest/cuda/ufunc.html\n",
    "- https://numba.pydata.org/numba-doc/dev/user/vectorize.html\n",
    "\n",
    "```\n",
    "The vectorize() decorator supports multiple ufunc targets:\n",
    "Target      Description\n",
    "cpu         Single-threaded CPU\n",
    "parallel    Multi-core CPU\n",
    "cuda        CUDA GPU\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU version\n",
    "@numba.vectorize(['float32(float32, float32)', \n",
    "                  'float64(float64, float64)'], target = 'cuda')\n",
    "def gpu_sincos(x, y):\n",
    "    return math.sin(x) * math.cos(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test it out\n",
    "- 2 input arrays\n",
    "- 1 output array\n",
    "- 1 million doubles (8 MB) per array\n",
    "- Total 24 MB of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: [numpy.allclose](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.allclose.html)  \n",
    "Returns True if two arrays are element-wise equal within a tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU vectorize correct:  True\n",
      "GPU vectorize correct:  True\n"
     ]
    }
   ],
   "source": [
    "# generate data\n",
    "n = 1000000\n",
    "x = np.linspace(0, np.pi, n)\n",
    "y = np.linspace(0, np.pi, n)\n",
    "\n",
    "# check result\n",
    "np_ans = np.sin(x) * np.cos(y)\n",
    "np_cpu_ans = cpu_sincos(x, y)\n",
    "np_gpu_ans = gpu_sincos(x, y)\n",
    "\n",
    "print(\"CPU vectorize correct: \", np.allclose(np_cpu_ans, np_ans))\n",
    "print(\"GPU vectorize correct: \", np.allclose(np_gpu_ans, np_ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy\n",
      "28.3 ms ± 14.6 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "CPU vectorize\n",
      "32.4 ms ± 67.9 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "GPU vectorize\n",
      "6.34 ms ± 141 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "print(\"Numpy\")\n",
    "%timeit np.sin(x) * np.cos(y)\n",
    "\n",
    "print(\"CPU vectorize\")\n",
    "%timeit cpu_sincos(x, y)\n",
    "\n",
    "print(\"GPU vectorize\")\n",
    "%timeit gpu_sincos(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
